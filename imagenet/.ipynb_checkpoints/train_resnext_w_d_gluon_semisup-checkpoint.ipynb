{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse,logging, os, math\n",
    "import mxnet as mx\n",
    "from mxnet import image\n",
    "from mxnet import nd, gluon, autograd, init\n",
    "from mxnet.gluon.data.vision import ImageFolderDataset\n",
    "from mxnet.gluon.data import DataLoader\n",
    "from mxnet.gluon import nn\n",
    "from tensorboardX import SummaryWriter\n",
    "import numpy as np\n",
    "import shutil\n",
    "import _pickle as cPickle\n",
    "from mxnet.gluon.parameter import Parameter, ParameterDict\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "from IPython.core.debugger import Tracer\n",
    "\n",
    "from resnext_w_d_maxmin import resnext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s - %(message)s')\n",
    "console = logging.StreamHandler()\n",
    "console.setFormatter(formatter)\n",
    "logger.addHandler(console)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Options:\n",
    "    def __init__(self):\n",
    "        self.gpus = '0,1,2,3,4,5,6,7' #the gpus will be used, e.g \"0,1,2,3\"\n",
    "        self.data_dir = '/tanData/datasets/imagenet/data' #the input data directory\n",
    "        self.log_dir = '/tanData/logs'\n",
    "        self.model_dir ='/tanData/models'\n",
    "        self.exp_name = 'semisup_exp1_128K'\n",
    "        self.data_type = 'imagenet' #the dataset type\n",
    "        self.depth = 50 #the depth of resnet\n",
    "        self.batch_size = 16 #the batch size\n",
    "        self.num_group = 64 #the number of convolution groups\n",
    "        self.drop_out = 0.0 #the probability of an element to be zeroed\n",
    "        self.alpha_max = 0.5\n",
    "        self.alpha_min = 0.5\n",
    "        self.alpha_drm = 0.5\n",
    "        self.alpha_rpn = 1.0\n",
    "        self.alpha_kl = 0.5\n",
    "        self.alpha_mm = 0.5\n",
    "        self.alpha_min = 0.5\n",
    "        self.alpha_max = 1.0 - self.alpha_min\n",
    "        \n",
    "        self.list_dir = './' #the directory which contain the training list file\n",
    "        self.lr = 0.1 #initialization learning rate\n",
    "        self.mom = 0.9 #momentum for sgd\n",
    "        self.bn_mom = 0.9 #momentum for batch normlization\n",
    "        self.wd = 0.0001 #weight decay for sgd\n",
    "        self.workspace = 512 #memory space size(MB) used in convolution, \n",
    "                            #if xpu memory is oom, then you can try smaller vale, such as --workspace 256 \n",
    "        self.num_classes = 1000 #the class number of your task\n",
    "        self.aug_level = 2 # level 1: use only random crop and random mirror, \n",
    "                           #level 2: add scale/aspect/hsv augmentation based on level 1, \n",
    "                           #level 3: add rotation/shear augmentation based on level 2 \n",
    "        self.num_examples = 1152000 # the number of training examples\n",
    "        self.kv_store = 'device' # the kvstore type'\n",
    "        self.model_load_epoch = 0 # load the model on an epoch using the model-load-prefix\n",
    "        self.frequent = 50 # frequency of logging\n",
    "        self.memonger = False # true means using memonger to save momory, https://github.com/dmlc/mxnet-memonger\n",
    "        self.retrain = False # true means continue training\n",
    "        \n",
    "args = Options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-23 04:30:59,487 - <__main__.Options object at 0x7f29ec260978>\n"
     ]
    }
   ],
   "source": [
    "hdlr = logging.FileHandler('./log/log-semi128Kresnext-{}-{}.log'.format(args.data_type, args.depth))\n",
    "hdlr.setFormatter(formatter)\n",
    "logger.addHandler(hdlr)\n",
    "logging.info(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kv = mx.kvstore.create(args.kv_store)\n",
    "ctx = mx.cpu() if args.gpus is None else [mx.gpu(int(i)) for i in args.gpus.split(',')]\n",
    "batch_size = args.batch_size\n",
    "batch_size *= max(1, len(ctx))\n",
    "begin_epoch = args.model_load_epoch if args.model_load_epoch else 0\n",
    "if not os.path.exists(\"./model\"):\n",
    "    os.mkdir(\"./model\")\n",
    "model_prefix = \"semi128Kresnext_{}_{}_{}_{}\".format(args.data_type, args.depth, kv.rank, args.exp_name)\n",
    "# model_prefix = \"model/se-resnext-{}-{}-{}\".format(args.data_type, args.depth, kv.rank)\n",
    "arg_params = None\n",
    "aux_params = None\n",
    "if args.retrain:\n",
    "    _, arg_params, aux_params = mx.model.load_checkpoint(model_prefix, args.model_load_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_sup = mx.io.ImageRecordIter(\n",
    "    path_imgrec         = os.path.join(args.data_dir, \"train.rec\") if args.data_type == 'cifar10' else\n",
    "                          os.path.join(args.data_dir, \"train_256_q90.rec\") if args.aug_level == 1\n",
    "                          else os.path.join(args.data_dir, \"train_sup_480.rec\") ,\n",
    "    label_width         = 1,\n",
    "    data_name           = 'data',\n",
    "    label_name          = 'softmax_label',\n",
    "    data_shape          = (3, 32, 32) if args.data_type==\"cifar10\" else (3, 224, 224),\n",
    "    batch_size          = batch_size // 2,\n",
    "    pad                 = 4 if args.data_type == \"cifar10\" else 0,\n",
    "    fill_value          = 127,  # only used when pad is valid\n",
    "    rand_crop           = True,\n",
    "    max_random_scale    = 1.0,  # 480 with imagnet, 32 with cifar10\n",
    "    min_random_scale    = 1.0 if args.data_type == \"cifar10\" else 1.0 if args.aug_level == 1 else 0.533,  # 256.0/480.0=0.533, 256.0/384.0=0.667 256.0/256=1.0\n",
    "    max_aspect_ratio    = 0 if args.data_type == \"cifar10\" else 0 if args.aug_level == 1 else 0.25, # 0.25\n",
    "    random_h            = 0 if args.data_type == \"cifar10\" else 0 if args.aug_level == 1 else 36,  # 0.4*90\n",
    "    random_s            = 0 if args.data_type == \"cifar10\" else 0 if args.aug_level == 1 else 50,  # 0.4*127\n",
    "    random_l            = 0 if args.data_type == \"cifar10\" else 0 if args.aug_level == 1 else 50,  # 0.4*127\n",
    "    max_rotate_angle    = 0 if args.aug_level <= 2 else 10,\n",
    "    max_shear_ratio     = 0 if args.aug_level <= 2 else 0.0, #0.1 args.aug_level = 3\n",
    "    rand_mirror         = True,\n",
    "    shuffle             = True,\n",
    "    num_parts           = kv.num_workers,\n",
    "    part_index          = kv.rank)\n",
    "\n",
    "train_data_unsup = mx.io.ImageRecordIter(\n",
    "    path_imgrec         = os.path.join(args.data_dir, \"train.rec\") if args.data_type == 'cifar10' else\n",
    "                          os.path.join(args.data_dir, \"train_256_q90.rec\") if args.aug_level == 1\n",
    "                          else os.path.join(args.data_dir, \"train_unsup_480.rec\") ,\n",
    "    label_width         = 1,\n",
    "    data_name           = 'data',\n",
    "    label_name          = 'softmax_label',\n",
    "    data_shape          = (3, 32, 32) if args.data_type==\"cifar10\" else (3, 224, 224),\n",
    "    batch_size          = batch_size // 2,\n",
    "    pad                 = 4 if args.data_type == \"cifar10\" else 0,\n",
    "    fill_value          = 127,  # only used when pad is valid\n",
    "    rand_crop           = True,\n",
    "    max_random_scale    = 1.0,  # 480 with imagnet, 32 with cifar10\n",
    "    min_random_scale    = 1.0 if args.data_type == \"cifar10\" else 1.0 if args.aug_level == 1 else 0.533,  # 256.0/480.0=0.533, 256.0/384.0=0.667 256.0/256=1.0\n",
    "    max_aspect_ratio    = 0 if args.data_type == \"cifar10\" else 0 if args.aug_level == 1 else 0.25, # 0.25\n",
    "    random_h            = 0 if args.data_type == \"cifar10\" else 0 if args.aug_level == 1 else 36,  # 0.4*90\n",
    "    random_s            = 0 if args.data_type == \"cifar10\" else 0 if args.aug_level == 1 else 50,  # 0.4*127\n",
    "    random_l            = 0 if args.data_type == \"cifar10\" else 0 if args.aug_level == 1 else 50,  # 0.4*127\n",
    "    max_rotate_angle    = 0 if args.aug_level <= 2 else 10,\n",
    "    max_shear_ratio     = 0 if args.aug_level <= 2 else 0.0, #0.1 args.aug_level = 3\n",
    "    rand_mirror         = True,\n",
    "    shuffle             = True,\n",
    "    num_parts           = kv.num_workers,\n",
    "    part_index          = kv.rank)\n",
    "\n",
    "val_data = mx.io.ImageRecordIter(\n",
    "    path_imgrec         = os.path.join(args.data_dir, \"val.rec\") if args.data_type == 'cifar10' else\n",
    "                          os.path.join(args.data_dir, \"val_256.rec\"),\n",
    "    label_width         = 1,\n",
    "    data_name           = 'data',\n",
    "    label_name          = 'softmax_label',\n",
    "    batch_size          = batch_size,\n",
    "    data_shape          = (3, 32, 32) if args.data_type==\"cifar10\" else (3, 224, 224),\n",
    "    rand_crop           = False,\n",
    "    rand_mirror         = False,\n",
    "    num_parts           = kv.num_workers,\n",
    "    part_index          = kv.rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normal(mx.init.Initializer):\n",
    "    \"\"\"Initializes weights with random values sampled from a normal distribution\n",
    "    with a mean and standard deviation of `sigma`.\n",
    "    \"\"\"\n",
    "    def __init__(self, mean=0, sigma=0.01):\n",
    "        super(Normal, self).__init__(sigma=sigma)\n",
    "        self.sigma = sigma\n",
    "        self.mean = mean\n",
    "\n",
    "    def _init_weight(self, _, arr):\n",
    "        mx.random.normal(self.mean, self.sigma, out=arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_factor_scheduler(begin_epoch, epoch_size, step=[30, 60, 90, 95, 110, 120], factor=0.1):\n",
    "    step_ = [epoch_size * (x-begin_epoch) for x in step if x-begin_epoch > 0]\n",
    "    return mx.lr_scheduler.MultiFactorScheduler(step=step_, factor=factor) if len(step_) else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "L2_loss = gluon.loss.L2Loss()\n",
    "\n",
    "acc_top1 = mx.metric.Accuracy()\n",
    "acc_top5 = mx.metric.TopKAccuracy(5)\n",
    "import datetime\n",
    "writer = SummaryWriter(os.path.join(args.log_dir, args.exp_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, val_data, ctx):\n",
    "    val_data.reset()\n",
    "    \n",
    "    acc_top1_val = mx.metric.Accuracy()\n",
    "    acc_top5_val = mx.metric.TopKAccuracy(5)\n",
    "    acc_top1_val_max = mx.metric.Accuracy()\n",
    "    acc_top5_val_max = mx.metric.TopKAccuracy(5)\n",
    "    acc_top1_val_min = mx.metric.Accuracy()\n",
    "    acc_top5_val_min = mx.metric.TopKAccuracy(5)\n",
    "    acc_top1_val.reset()\n",
    "    acc_top5_val.reset()\n",
    "    acc_top1_val_max.reset()\n",
    "    acc_top5_val_max.reset()\n",
    "    acc_top1_val_min.reset()\n",
    "    acc_top5_val_min.reset()\n",
    "    for i, batch in enumerate(val_data):\n",
    "        data = gluon.utils.split_and_load(batch.data[0], ctx_list=ctx, batch_axis=0)\n",
    "        label = gluon.utils.split_and_load(batch.label[0], ctx_list=ctx, batch_axis=0)\n",
    "        \n",
    "        outputs = []\n",
    "        outputsmax = []\n",
    "        outputsmin = []\n",
    "        for x, y in zip(data, label):\n",
    "            x = x.astype('float16', copy=False)\n",
    "            y = y.astype('float16', copy=False)\n",
    "            cond = nd.zeros_like(y)\n",
    "            zmax, zmin, _, _, _, _, _, _ = net(x, y, cond)\n",
    "            z = args.alpha_max * zmax + args.alpha_min * zmin\n",
    "            outputs.append(z)\n",
    "            outputsmax.append(zmax)\n",
    "            outputsmin.append(zmin)\n",
    "            \n",
    "            \n",
    "        acc_top1_val.update(label, outputs)\n",
    "        acc_top5_val.update(label, outputs)\n",
    "        acc_top1_val_max.update(label, outputsmax)\n",
    "        acc_top5_val_max.update(label, outputsmax)\n",
    "        acc_top1_val_min.update(label, outputsmin)\n",
    "        acc_top5_val_min.update(label, outputsmin)\n",
    "\n",
    "    _, top1 = acc_top1_val.get()\n",
    "    _, top5 = acc_top5_val.get()\n",
    "    _, top1max = acc_top1_val_max.get()\n",
    "    _, top5max = acc_top5_val_max.get()\n",
    "    _, top1min = acc_top1_val_min.get()\n",
    "    _, top5min = acc_top5_val_min.get()\n",
    "    return (top1, top5, top1max, top5max, top1min, top5min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_data_sup, train_data_unsup, val_data, num_epochs, ctx):\n",
    "    epoch_size = max(int(args.num_examples / (batch_size//2) / kv.num_workers), 1)\n",
    "    lr_sch = multi_factor_scheduler(begin_epoch, epoch_size, step=[30, 60, 90, 95, 110, 120], factor=0.1)\n",
    "    trainer = gluon.Trainer(net.collect_params(), 'nag', {'learning_rate':args.lr, 'momentum':args.mom, 'wd':args.wd, 'lr_scheduler': lr_sch, 'multi_precision': True})\n",
    "    \n",
    "    prev_time = datetime.datetime.now()\n",
    "    best_top1_val = 0.; best_top1_valmax = 0.; best_top1_valmin = 0.\n",
    "    best_top5_val = 0.; best_top5_valmax = 0.; best_top5_valmin = 0.\n",
    "    log_interval = 100\n",
    "    \n",
    "    for epoch in range(begin_epoch, num_epochs):\n",
    "        train_data_sup.reset()\n",
    "        train_data_unsup.reset()\n",
    "        \n",
    "        tic = time.time()\n",
    "        btic = time.time()\n",
    "        acc_top1.reset()\n",
    "        acc_top5.reset()\n",
    "        train_loss = 0\n",
    "        num_batch = 0\n",
    "        \n",
    "        for i, (batch_sup, batch_unsup) in enumerate(zip(train_data_sup, train_data_unsup)):\n",
    "            bs = batch_unsup.data[0].shape[0]\n",
    "            \n",
    "            data_sup = gluon.utils.split_and_load(batch_sup.data[0], ctx_list=ctx, batch_axis=0)\n",
    "            label_sup = gluon.utils.split_and_load(batch_sup.label[0], ctx_list=ctx, batch_axis=0)\n",
    "            data_unsup = gluon.utils.split_and_load(batch_unsup.data[0], ctx_list=ctx, batch_axis=0)\n",
    "            label_unsup = gluon.utils.split_and_load(batch_unsup.label[0], ctx_list=ctx, batch_axis=0)\n",
    "            \n",
    "            loss = []\n",
    "            outputs = []\n",
    "            \n",
    "            with autograd.record():\n",
    "                for x_sup, x_unsup, y_sup, y_unsup in zip(data_sup, data_unsup, label_sup, label_unsup):\n",
    "                    x_sup = x_sup.astype('float16', copy=False)\n",
    "                    x_unsup = x_unsup.astype('float16', copy=False)\n",
    "                    y_sup = y_sup.astype('float16', copy=False)\n",
    "                    y_unsup = y_unsup.astype('float16', copy=False)\n",
    "                    \n",
    "                    cond_sup = nd.ones_like(y_sup)\n",
    "                    zmax_sup, zmin_sup, xhatmax_sup, xhatmin_sup, loss_mmmax_sup, loss_mmmin_sup, rpnmax_sup, rpnmin_sup = net(x_sup, y_sup, cond_sup)\n",
    "                    loss_xent_sup = args.alpha_max * criterion(zmax_sup, y_sup) + args.alpha_min * criterion(zmin_sup, y_sup)\n",
    "                    loss_drm_sup = args.alpha_max * L2_loss(xhatmax_sup, x_sup) + args.alpha_min * L2_loss(xhatmin_sup, x_sup)\n",
    "                    softmax_scores_sup = args.alpha_max * nd.softmax(zmax_sup) + args.alpha_min * nd.softmax(zmin_sup)\n",
    "                    loss_kl_sup = -nd.sum(nd.log(1000.0*softmax_scores_sup + 1e-8) * softmax_scores_sup, axis=1)\n",
    "                    loss_mm_sup = args.alpha_max * loss_mmmax_sup + args.alpha_min * loss_mmmin_sup\n",
    "                    rpn_sup = args.alpha_max * rpnmax_sup + args.alpha_min * rpnmin_sup\n",
    "                    loss_total_sup = loss_xent_sup + args.alpha_drm * loss_drm_sup + args.alpha_kl * loss_kl_sup + args.alpha_mm * loss_mm_sup + args.alpha_rpn * rpn_sup\n",
    "                    \n",
    "                    cond_unsup = nd.zeros_like(y_unsup)\n",
    "                    zmax_unsup, zmin_unsup, xhatmax_unsup, xhatmin_unsup, loss_mmmax_unsup, loss_mmmin_unsup, rpnmax_unsup, rpnmin_unsup = net(x_unsup, y_unsup, cond_unsup)\n",
    "                    loss_drm_unsup = args.alpha_max * L2_loss(xhatmax_unsup, x_unsup) + args.alpha_min * L2_loss(xhatmin_unsup, x_unsup)\n",
    "                    softmax_scores_unsup = args.alpha_max * nd.softmax(zmax_unsup) + args.alpha_min * nd.softmax(zmin_unsup)\n",
    "                    loss_kl_unsup = -nd.sum(nd.log(1000.0*softmax_scores_unsup + 1e-8) * softmax_scores_unsup, axis=1)\n",
    "                    loss_mm_unsup = args.alpha_max * loss_mmmax_unsup + args.alpha_min * loss_mmmin_unsup\n",
    "                    rpn_unsup = args.alpha_max * rpnmax_unsup + args.alpha_min * rpnmin_unsup\n",
    "                    loss_total_unsup = args.alpha_drm * loss_drm_unsup + args.alpha_kl * loss_kl_unsup + args.alpha_mm * loss_mm_unsup + args.alpha_rpn * rpn_unsup\n",
    "                    \n",
    "                    z_sup = args.alpha_max * zmax_sup + args.alpha_min * zmin_sup\n",
    "\n",
    "                    loss.append(loss_total_sup + loss_total_unsup)\n",
    "                    outputs.append(z_sup)\n",
    "                    \n",
    "            for l in loss:\n",
    "                l.backward()\n",
    "                \n",
    "            trainer.step(bs)\n",
    "            \n",
    "            acc_top1.update(label_sup, outputs)\n",
    "            acc_top5.update(label_sup, outputs)\n",
    "            train_loss += sum([l.sum().asscalar() for l in loss])\n",
    "            num_batch += 1\n",
    "            if log_interval and not i % log_interval:\n",
    "                _, top1 = acc_top1.get()\n",
    "                _, top5 = acc_top5.get()\n",
    "                logging.info('Epoch[%d] Batch [%d] Lr: %f     Speed: %f samples/sec   top1-acc=%f     top5-acc=%f'%(\n",
    "                          epoch, i, trainer.learning_rate, batch_size*log_interval/(time.time()-btic), top1, top5))\n",
    "                btic = time.time()\n",
    "        \n",
    "        _, top1 = acc_top1.get()\n",
    "        _, top5 = acc_top5.get()\n",
    "        train_loss /= num_batch * batch_size\n",
    "        writer.add_scalars('acc', {'train_top1': top1}, epoch)\n",
    "        writer.add_scalars('acc', {'train_top5': top5}, epoch)\n",
    "        \n",
    "        top1_val, top5_val, top1_valmax, top5_valmax, top1_valmin, top5_valmin = test(net=net, val_data=val_data, ctx=ctx)\n",
    "        \n",
    "        if top1_val > best_top1_val:\n",
    "            best_top1_val = top1_val\n",
    "            net.collect_params().save('%s/%s_best_top1.params'%(args.model_dir, model_prefix))\n",
    "        \n",
    "        if top1_valmax > best_top1_valmax:\n",
    "            best_top1_valmax = top1_valmax\n",
    "            net.collect_params().save('%s/%s_best_top1_max.params'%(args.model_dir, model_prefix))\n",
    "            \n",
    "        if top1_valmin > best_top1_valmin:\n",
    "            best_top1_valmin = top1_valmin\n",
    "            net.collect_params().save('%s/%s_best_top1_min.params'%(args.model_dir, model_prefix))\n",
    "        \n",
    "        if top5_val > best_top5_val:\n",
    "            best_top5_val = top5_val\n",
    "            net.collect_params().save('%s/%s_best_top5.params'%(args.model_dir, model_prefix))\n",
    "        \n",
    "        if top5_valmax > best_top5_valmax:\n",
    "            best_top5_valmax = top5_valmax\n",
    "            net.collect_params().save('%s/%s_best_top5_max.params'%(args.model_dir, model_prefix))\n",
    "        \n",
    "        if top5_valmin > best_top5_valmin:\n",
    "            best_top5_valmin = top5_valmin\n",
    "            net.collect_params().save('%s/%s_best_top5_min.params'%(args.model_dir, model_prefix))\n",
    "        \n",
    "        logging.info('[Epoch %d] training: acc-top1=%f acc-top5=%f loss=%f lr=%f'%(epoch, top1, top5, train_loss, trainer.learning_rate))\n",
    "        logging.info('[Epoch %d] time cost: %f'%(epoch, time.time()-tic))\n",
    "        logging.info('[Epoch %d] validation: acc-top1=%f acc-top5=%f best-acc-top1=%f best-acc-top5=%f'%(epoch, top1_val, top5_val, best_top1_val, best_top5_val))\n",
    "        logging.info('[Epoch %d] validation: acc-top1-max=%f acc-top5-max=%f best-acc-top1-max=%f best-acc-top5-max=%f'%(epoch, top1_valmax, top5_valmax, best_top1_valmax, best_top5_valmax))\n",
    "        logging.info('[Epoch %d] validation: acc-top1-min=%f acc-top5-min=%f best-acc-top1-min=%f best-acc-top5-min=%f'%(epoch, top1_valmin, top5_valmin, best_top1_valmin, best_top5_valmin))\n",
    "        \n",
    "        writer.add_scalars('acc', {'valid_top1': top1_val}, epoch)\n",
    "        writer.add_scalars('acc', {'valid_top5': top5_val}, epoch)\n",
    "        writer.add_scalars('acc', {'valid_top1_max': top1_valmax}, epoch)\n",
    "        writer.add_scalars('acc', {'valid_top5_max': top5_valmax}, epoch)\n",
    "        writer.add_scalars('acc', {'valid_top1_min': top1_valmin}, epoch)\n",
    "        writer.add_scalars('acc', {'valid_top5_min': top5_valmin}, epoch)\n",
    "        \n",
    "        net.collect_params().save('%s/%s_current.params'%(args.model_dir, model_prefix))\n",
    "        if not epoch % 10:\n",
    "            net.collect_params().save('%s/%s_epoch_%i.params'%(args.model_dir, model_prefix, epoch))\n",
    "    \n",
    "    return best_top1_val, best_top5_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_list = [0.25, 0.125, 0.0625, 0.03125]   # 1/4, 1/8, 1/16, 1/32\n",
    "if args.depth == 18:\n",
    "    units = [2, 2, 2, 2]\n",
    "elif args.depth == 34:\n",
    "    units = [3, 4, 6, 3]\n",
    "elif args.depth == 50:\n",
    "    units = [3, 4, 6, 3]\n",
    "elif args.depth == 101:\n",
    "    units = [3, 4, 23, 3]\n",
    "elif args.depth == 152:\n",
    "    units = [3, 8, 36, 3]\n",
    "elif args.depth == 200:\n",
    "    units = [3, 24, 36, 3]\n",
    "elif args.depth == 269:\n",
    "    units = [3, 30, 48, 8]\n",
    "else:\n",
    "    raise ValueError(\"no experiments done on detph {}, you can do it youself\".format(args.depth))\n",
    "\n",
    "num_epochs = 200 if args.data_type == \"cifar10\" else 125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train(ctx): \n",
    "    model = resnext(units=units, num_stage=4, filter_list=[64, 256, 512, 1024, 2048] if args.depth >=50 else [64, 64, 128, 256, 512], ratio_list=ratio_list, num_class=args.num_classes, num_group=args.num_group, data_type=\"imagenet\", drop_out=args.drop_out, bn_mom=args.bn_mom)\n",
    "    # model.collect_params().load('/tanData/models/seresnext_imagenet_50_0_exp1_current.params', ctx=ctx)\n",
    "    for param in model.collect_params().values():\n",
    "        if param.name.find('conv') != -1 or param.name.find('dense') != -1:\n",
    "            if param.name.find('weight') != -1:\n",
    "                param.initialize(init=mx.init.Xavier(rnd_type='gaussian', factor_type=\"in\", magnitude=2), ctx=ctx)\n",
    "            else:\n",
    "                param.initialize(init=mx.init.Zero(), ctx=ctx)\n",
    "        elif param.name.find('batchnorm') != -1:\n",
    "            if param.name.find('gamma') != -1:\n",
    "                param.initialize(init=Normal(mean=1, sigma=0.02), ctx=ctx)\n",
    "            else:\n",
    "                param.initialize(init=mx.init.Zero(), ctx=ctx)\n",
    "        elif param.name.find('insnorm') != -1:\n",
    "            if param.name.find('gamma') != -1:\n",
    "                param.initialize(init=Normal(mean=1, sigma=0.02), ctx=ctx)\n",
    "            else:\n",
    "                param.initialize(init=mx.init.Zero(), ctx=ctx)\n",
    "        elif param.name.find('biasadder') != -1:\n",
    "            param.initialize(init=mx.init.Zero(), ctx=ctx)\n",
    "        else:\n",
    "            param.initialize(init=mx.init.Xavier(rnd_type='gaussian', factor_type=\"in\", magnitude=2), ctx=ctx)\n",
    "                  \n",
    "    model.hybridize()\n",
    "    model.cast('float16')\n",
    "        \n",
    "    best_top1_val, best_top5_val = train(net=model, train_data_sup=train_data_sup, train_data_unsup=train_data_unsup, val_data=val_data, num_epochs=num_epochs, ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rpnmin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-fb1172a77304>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-8d6b51d88591>\u001b[0m in \u001b[0;36mrun_train\u001b[0;34m(ctx)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float16'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mbest_top1_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_top5_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_sup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data_sup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_unsup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data_unsup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-d413287ffae4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, train_data_sup, train_data_unsup, val_data, num_epochs, ctx)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                     \u001b[0mcond_sup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_sup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                     \u001b[0mzmax_sup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzmin_sup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxhatmax_sup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxhatmin_sup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_mmmax_sup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_mmmin_sup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrpnmax_sup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrpnmin_sup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_sup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_sup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond_sup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m                     \u001b[0mloss_xent_sup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha_max\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzmax_sup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_sup\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha_min\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzmin_sup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_sup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                     \u001b[0mloss_drm_sup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha_max\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mL2_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxhatmax_sup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_sup\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha_min\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mL2_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxhatmin_sup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_sup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/incubator-mxnet/python/mxnet/gluon/block.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    540\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/incubator-mxnet/python/mxnet/gluon/block.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_cached_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/incubator-mxnet/python/mxnet/gluon/block.py\u001b[0m in \u001b[0;36m_call_cached_op\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    797\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_cached_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_op\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/incubator-mxnet/python/mxnet/gluon/block.py\u001b[0m in \u001b[0;36m_build_cache\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_build_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m         \u001b[0mdata_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/incubator-mxnet/python/mxnet/gluon/block.py\u001b[0m in \u001b[0;36m_get_graph\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    741\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reg_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhybrid_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mgrouped_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=no-value-for-parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    744\u001b[0m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_out_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/DRMM/classification/cifar/resnext_w_d_maxmin_v2.py\u001b[0m in \u001b[0;36mhybrid_forward\u001b[0;34m(self, F, x, y, cond)\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0mxmu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m         \u001b[0mxhatmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxhatmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_mmmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_mmmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrpnmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrpnmin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopdown_stages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mahatmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mahatmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthatmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthatmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeanfwmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeanfwmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvarfwmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvarfwmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbfw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mahatmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mahatmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthatmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthatmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeanfwmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeanfwmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvarfwmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvarfwmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbfw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/DRMM/classification/cifar/resnext_w_d_maxmin_v2.py\u001b[0m in \u001b[0;36mtopdown\u001b[0;34m(self, F, net, x, ahatmax, ahatmin, thatmax, thatmin, meanfwmax, meanfwmin, varfwmax, varfwmin, bfw)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtd_unit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeanmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeanmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvarmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvarmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mahatmax\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mahatmin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeanfwmax\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeanfwmin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvarfwmax\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvarfwmin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbfw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0mxmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_mmmax_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_mmmin_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrpnmax_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrpnmin_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtd_unit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeanmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeanmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvarmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvarmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m                 \u001b[0mloss_mmmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_mmmax_res\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/incubator-mxnet/python/mxnet/gluon/block.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    540\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/incubator-mxnet/python/mxnet/gluon/block.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m    924\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reg_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhybrid_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhybrid_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/DRMM/classification/cifar/resnext_w_d_maxmin_v2.py\u001b[0m in \u001b[0;36mhybrid_forward\u001b[0;34m(self, F, xmax, xmin, ahatmax, ahatmin, meanfwmax, varfwmax, meanfwmin, varfwmin, bfw)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0mxmin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxmin\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mshortcutmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mxmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_mmmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_mmmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrpnmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrpnmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mresnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHybridBlock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rpnmin' is not defined"
     ]
    }
   ],
   "source": [
    "run_train(ctx=ctx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_python3)",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
