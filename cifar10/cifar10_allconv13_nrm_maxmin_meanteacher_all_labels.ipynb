{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import mxnet as mx\n",
    "from mxnet import image\n",
    "from mxnet import nd, gluon, autograd, init\n",
    "from mxnet.gluon.data.vision import ImageFolderDataset\n",
    "from mxnet.gluon.data import DataLoader\n",
    "from mxnet.gluon import nn\n",
    "from tensorboardX import SummaryWriter\n",
    "import numpy as np\n",
    "import shutil\n",
    "import _pickle as cPickle\n",
    "from sklearn import preprocessing\n",
    "from mxnet.gluon.parameter import Parameter, ParameterDict\n",
    "from common.util import download_file\n",
    "import subprocess\n",
    "\n",
    "from IPython.core.debugger import Tracer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Options:\n",
    "    def __init__(self):\n",
    "        self.seed_val = 0\n",
    "        self.num_train_sup = 50000\n",
    "        self.batch_size = 100\n",
    "        self.data_dir = '/tanData/datasets/cifar10'\n",
    "        self.log_dir = '/tanData/logs'\n",
    "        self.model_dir ='/tanData/models'\n",
    "        self.exp_name = 'cifar10_nlabels_%i_allconv13_lddrm_mm_pathnorm_min_max_meanteacher_seed_%i'%(self.num_train_sup, self.seed_val)\n",
    "        self.ctx = mx.gpu(0)\n",
    "        self.alpha_drm = 0.5\n",
    "        self.alpha_pn = 1.0\n",
    "        self.alpha_kl = 0.5\n",
    "        self.alpha_nn = 0.5\n",
    "        self.alpha_min = 0.5\n",
    "        self.alpha_max = 1.0 - self.alpha_min\n",
    "        self.alpha_consistent = 33.0\n",
    "        \n",
    "        self.use_bias = True\n",
    "        self.use_bn = True\n",
    "        self.do_topdown = True\n",
    "        self.do_countpath = False\n",
    "        self.do_pn = True\n",
    "        self.relu_td = False\n",
    "        self.do_nn = True\n",
    "        self.min_max = True\n",
    "\n",
    "opt = Options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the data step 1\n",
    "with open(os.path.join(opt.data_dir, 'trainLabels.csv'), 'r') as f:\n",
    "    lines = f.readlines()[1:]\n",
    "    tokens = [i.rstrip().split(',') for i in lines]\n",
    "    idx_label = dict((int(idx), label) for idx, label in tokens)\n",
    "labels = set(idx_label.values())\n",
    "\n",
    "num_train = len(os.listdir(os.path.join(opt.data_dir, 'train')))\n",
    "\n",
    "num_train_tuning = int(num_train * (1 - 0.1))\n",
    "\n",
    "num_train_tuning_per_label = num_train_tuning // len(labels)\n",
    "\n",
    "num_train_sup = opt.num_train_sup\n",
    "\n",
    "num_train_sup_per_label = num_train_sup // len(labels)\n",
    "\n",
    "ratio_unsup_sup = (num_train - num_train_sup) // num_train_sup\n",
    "\n",
    "# select labeled data\n",
    "data_rng = np.random.RandomState(opt.seed_val)\n",
    "indx = data_rng.permutation(range(1, num_train + 1))\n",
    "indx_sup = []\n",
    "\n",
    "for c in labels:\n",
    "    c_count = 0\n",
    "    for i in indx:\n",
    "        if idx_label[i] == c and c_count < num_train_sup_per_label:\n",
    "            indx_sup.append(i)\n",
    "            c_count += 1\n",
    "        if c_count >= num_train_sup_per_label:\n",
    "            break\n",
    "            \n",
    "label_count = dict()\n",
    "# print(indx_sup)\n",
    "# for i in indx_sup:\n",
    "#     print(idx_label[i])\n",
    "\n",
    "def mkdir_if_not_exist(path):\n",
    "    if not os.path.exists(os.path.join(*path)):\n",
    "        os.makedirs(os.path.join(*path))\n",
    "        \n",
    "for train_file in os.listdir(os.path.join(opt.data_dir, 'train')):\n",
    "    idx = int(train_file.split('.')[0])\n",
    "    label = idx_label[idx]\n",
    "    if idx in indx_sup:\n",
    "        mkdir_if_not_exist([opt.data_dir, 'train_valid_sup_nsup_%i_seed_%i'%(opt.num_train_sup, opt.seed_val), label])\n",
    "        for i in range(ratio_unsup_sup):\n",
    "            shutil.copy(os.path.join(opt.data_dir,'train', train_file),\n",
    "                        os.path.join(opt.data_dir, 'train_valid_sup_nsup_%i_seed_%i'%(opt.num_train_sup, opt.seed_val), label, '%i_%i.png'%(idx, i)))\n",
    "    else:\n",
    "        mkdir_if_not_exist([opt.data_dir, 'train_valid_unsup_nsup_%i_seed_%i'%(opt.num_train_sup, opt.seed_val), label])\n",
    "        shutil.copy(os.path.join(opt.data_dir,'train', train_file),\n",
    "                   os.path.join(opt.data_dir, 'train_valid_unsup_nsup_%i_seed_%i'%(opt.num_train_sup, opt.seed_val), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$opt.num_train_sup\" \"$opt.seed_val\"\n",
    "DATA_DIR=/tanData/datasets/cifar10\n",
    "data_name=( \"train_valid_sup_nsup_$1_seed_$2\" \"train_valid_unsup_nsup_$1_seed_$2\" )\n",
    "list_name=( \"cifar10_train_valid_sup_nsup_$1_seed_$2\" \"cifar10_train_valid_unsup_nsup_$1_seed_$2\" )\n",
    "MX_DIR=/mxnet\n",
    "\n",
    "for ((i=0;i<${#data_name[@]};++i)); do\n",
    "    # clean stuffs\n",
    "    rm -rf ${DATA_DIR}/${list_name[i]}.*\n",
    "    # make list for all classes\n",
    "    python ${MX_DIR}/tools/im2rec.py --list --exts '.png' --recursive ${DATA_DIR}/${list_name[i]} ${DATA_DIR}/${data_name[i]}\n",
    "    # make .rec file for all classes\n",
    "    python ${MX_DIR}/tools/im2rec.py --exts '.png' --quality 95 --num-thread 16 --color 1 ${DATA_DIR}/${list_name[i]} ${DATA_DIR}/${data_name[i]}\n",
    "    # remove folders\n",
    "    rm -rf ${DATA_DIR}/${data_name[i]}\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_device(ctx=mx.gpu(0)):\n",
    "    try:\n",
    "        _ = mx.nd.array([1, 2, 3], ctx=ctx)\n",
    "    except mx.MXNetError:\n",
    "        return None\n",
    "    return ctx\n",
    "\n",
    "assert gpu_device(opt.ctx), 'No GPU device found!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join(opt.log_dir, opt.exp_name)\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shape = (3, 32, 32)\n",
    "train_data_sup = mx.io.ImageRecordIter(\n",
    "    path_imgrec = os.path.join(opt.data_dir,'cifar10_train.rec'),\n",
    "    data_shape  = data_shape,\n",
    "    batch_size  = opt.batch_size,\n",
    "    mean_r             = 125.3,\n",
    "    mean_g             = 123.0,\n",
    "    mean_b             = 113.9,\n",
    "    std_r              = 63.0,\n",
    "    std_g              = 62.1,\n",
    "    std_b              = 66.7,\n",
    "    shuffle = True,\n",
    "    ## Data augmentation\n",
    "    rand_crop   = True,\n",
    "    max_crop_size = 32,\n",
    "    min_crop_size = 32,\n",
    "    pad = 4,\n",
    "    fill_value = 0,\n",
    "    rand_mirror = True)\n",
    "valid_data = mx.io.ImageRecordIter(\n",
    "    path_imgrec = os.path.join(opt.data_dir,'cifar10_val.rec'),\n",
    "    data_shape  = data_shape,\n",
    "    batch_size  = opt.batch_size,\n",
    "    mean_r             = 125.3,\n",
    "    mean_g             = 123.0,\n",
    "    mean_b             = 113.9,\n",
    "    std_r              = 63.0,\n",
    "    std_g              = 62.1,\n",
    "    std_b              = 66.7,\n",
    "    ## No data augmentation\n",
    "    rand_crop   = False,\n",
    "    rand_mirror = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "L2_loss = gluon.loss.L2Loss()\n",
    "L1_loss = gluon.loss.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normal(mx.init.Initializer):\n",
    "    \"\"\"Initializes weights with random values sampled from a normal distribution\n",
    "    with a mean and standard deviation of `sigma`.\n",
    "    \"\"\"\n",
    "    def __init__(self, mean=0, sigma=0.01):\n",
    "        super(Normal, self).__init__(sigma=sigma)\n",
    "        self.sigma = sigma\n",
    "        self.mean = mean\n",
    "\n",
    "    def _init_weight(self, _, arr):\n",
    "        mx.random.normal(self.mean, self.sigma, out=arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from resnet import ResNet164_v2\n",
    "from mxnet.gluon.model_zoo import vision as models\n",
    "from nrm_maxmin import NRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "writer = SummaryWriter(os.path.join(opt.log_dir, opt.exp_name))\n",
    "\n",
    "def get_acc(output, label):\n",
    "    pred = output.argmax(1, keepdims=False)\n",
    "    correct = (pred == label).sum()\n",
    "    return correct.asscalar()\n",
    "\n",
    "def extract_acts(net, x, layer_indx):\n",
    "    start_layer = 0\n",
    "    out = []\n",
    "    for i in layer_indx:\n",
    "        for block in net.features._children[start_layer:i]:\n",
    "            x = block(x)\n",
    "        out.append(x)\n",
    "        start_layer = i\n",
    "    return out\n",
    "\n",
    "def update_ema_variables(model, ema_model, alpha, global_step):\n",
    "    # Use the true average until the exponential average is more correct\n",
    "    alpha = min(1 - 1 / (global_step + 1), alpha)\n",
    "    for ema_param, param in zip(ema_model.collect_params().values(), model.collect_params().values()):\n",
    "        ema_param.set_data(alpha * ema_param.data() + (1 - alpha) * param.data())\n",
    "\n",
    "def test(net, valid_data, ctx):\n",
    "    valid_data.reset()\n",
    "    valid_loss = 0; valid_loss_xentropy = 0; valid_loss_drm = 0; valid_loss_pn = 0; valid_loss_kl = 0; valid_loss_nn = 0\n",
    "    valid_correct = 0; valid_total = 0; valid_correct2 = 0; valid_correctmax = 0; valid_correctmin = 0\n",
    "    num_batch_valid = 0\n",
    "    for batch in valid_data:\n",
    "        bs = batch.data[0].shape[0]\n",
    "        data = batch.data[0].as_in_context(ctx)\n",
    "        label = batch.label[0].as_in_context(ctx)\n",
    "        [output, output_min, xhat, xhat_min, _, loss_pn, loss_nn] = net(data, label)\n",
    "        loss_xentropy = opt.alpha_max * criterion(output, label) + opt.alpha_min * criterion(output_min, label)\n",
    "        loss_drm = opt.alpha_max * L2_loss(xhat, data) + opt.alpha_min * L2_loss(xhat_min, data)\n",
    "        softmax_val = opt.alpha_max * nd.softmax(output) + opt.alpha_min * nd.softmax(output_min)\n",
    "        loss_kl = -nd.sum(nd.log(10.0*softmax_val + 1e-8) * softmax_val, axis=1)\n",
    "        loss = loss_xentropy + opt.alpha_drm * loss_drm + opt.alpha_kl * loss_kl + opt.alpha_nn * loss_nn + opt.alpha_pn * loss_pn\n",
    "\n",
    "        valid_loss_xentropy += nd.mean(loss_xentropy).asscalar()\n",
    "        valid_loss_drm += nd.mean(loss_drm).asscalar()\n",
    "        valid_loss_pn += nd.mean(loss_pn).asscalar()\n",
    "        valid_loss_kl += nd.mean(loss_kl).asscalar()\n",
    "        valid_loss_nn += nd.mean(loss_nn).asscalar()\n",
    "        valid_loss += nd.mean(loss).asscalar()\n",
    "        valid_correct += get_acc(opt.alpha_max * output + opt.alpha_min * output_min, label)\n",
    "        valid_correct2 += opt.alpha_max * get_acc(output, label) + opt.alpha_min * get_acc(output_min, label)\n",
    "        valid_correctmax += get_acc(output, label)\n",
    "        valid_correctmin += get_acc(output_min, label)\n",
    "\n",
    "        valid_total += bs\n",
    "        num_batch_valid += 1\n",
    "    valid_acc = valid_correct / valid_total\n",
    "    valid_acc2 = valid_correct2 / valid_total\n",
    "    valid_accmax = valid_correctmax / valid_total\n",
    "    valid_accmin = valid_correctmin / valid_total\n",
    "    return valid_acc, valid_acc2, valid_accmax, valid_accmin, valid_loss_xentropy, valid_loss_drm, valid_loss_pn, valid_loss_kl, valid_loss_nn, valid_loss, num_batch_valid\n",
    "\n",
    "def write_results(writer, name, valid_acc, valid_acc2, valid_accmax, valid_accmin, valid_loss_xentropy, valid_loss_drm, valid_loss_pn, valid_loss_kl, valid_loss_nn, valid_loss, num_batch_valid, epoch):\n",
    "    writer.add_scalars('loss', {'%s'%name: valid_loss / num_batch_valid}, epoch)\n",
    "    writer.add_scalars('loss_xentropy', {'%s'%name: valid_loss_xentropy / num_batch_valid}, epoch)\n",
    "    writer.add_scalars('loss_drm', {'%s'%name: valid_loss_drm / num_batch_valid}, epoch)\n",
    "    writer.add_scalars('loss_pn', {'%s'%name: valid_loss_pn / num_batch_valid}, epoch)\n",
    "    writer.add_scalars('loss_kl', {'%s'%name: valid_loss_kl / num_batch_valid}, epoch)\n",
    "    writer.add_scalars('loss_nn', {'%s'%name: valid_loss_nn / num_batch_valid}, epoch)\n",
    "    writer.add_scalars('acc', {'%s'%name: valid_acc}, epoch)\n",
    "    writer.add_scalars('acc', {'%s_2'%name: valid_acc2}, epoch)\n",
    "    writer.add_scalars('acc', {'%s_max'%name: valid_accmax}, epoch)\n",
    "    writer.add_scalars('acc', {'%s_min'%name: valid_accmin}, epoch)\n",
    "    \n",
    "def save_best(net, name, valid_acc, valid_acc2, valid_accmax, valid_accmin, best_valid_acc, best_valid_acc2, best_valid_accmax, best_valid_accmin):\n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "        net.collect_params().save('%s/%s_%s.params'%(opt.model_dir, name, opt.exp_name))\n",
    "    if valid_acc2 > best_valid_acc2:\n",
    "        best_valid_acc2 = valid_acc2\n",
    "        net.collect_params().save('%s/%s_%s_2.params'%(opt.model_dir, name, opt.exp_name))\n",
    "    if valid_accmax > best_valid_accmax:\n",
    "        best_valid_accmax = valid_accmax\n",
    "        net.collect_params().save('%s/%s_%s_max.params'%(opt.model_dir, name, opt.exp_name))\n",
    "    if valid_accmin > best_valid_accmin:\n",
    "        best_valid_accmin = valid_accmin\n",
    "        net.collect_params().save('%s/%s_%s_min.params'%(opt.model_dir, name, opt.exp_name))\n",
    "    return best_valid_acc, best_valid_acc2, best_valid_accmax, best_valid_accmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, ema_net, train_data_sup, valid_data, num_epochs, lr, wd, ctx, lr_decay, relu_indx):\n",
    "    trainer = gluon.Trainer(\n",
    "        net.collect_params(), 'adam', {'learning_rate': 0.001, 'wd': wd})\n",
    "    \n",
    "    prev_time = datetime.datetime.now()\n",
    "    best_valid_acc = 0; best_valid_acc2 = 0; best_valid_accmax = 0; best_valid_accmin = 0\n",
    "    best_valid_acc_ema = 0; best_valid_acc_ema2 = 0; best_valid_acc_emamax = 0; best_valid_acc_emamin = 0\n",
    "    iter_indx = 0\n",
    "    global_step = 0\n",
    "    \n",
    "    for epoch in range(num_epochs-100):\n",
    "        train_data_sup.reset()\n",
    "        train_loss = 0; train_loss_xentropy = 0; train_loss_drm = 0; train_loss_pn = 0; train_loss_kl = 0; train_loss_nn = 0\n",
    "        correct = 0; total = 0; correct2=0; correctmax=0; correctmin=0\n",
    "        num_batch_train = 0\n",
    "        \n",
    "        if epoch == 20:\n",
    "            sgd_lr = 0.15\n",
    "            decay_val = np.exp(np.log(sgd_lr / 0.0001) / (num_epochs - 2))\n",
    "            sgd_lr = sgd_lr * decay_val\n",
    "            trainer = gluon.Trainer(net.collect_params(), 'SGD', {'learning_rate': sgd_lr, 'wd': wd})\n",
    "            \n",
    "        if epoch >= 20:\n",
    "            trainer.set_learning_rate(trainer.learning_rate / decay_val)\n",
    "        \n",
    "        for batch_sup in train_data_sup:\n",
    "            bs = batch_sup.data[0].shape[0]\n",
    "            data_sup = batch_sup.data[0].as_in_context(ctx)\n",
    "            label_sup = batch_sup.label[0].as_in_context(ctx)\n",
    "            with autograd.record():\n",
    "                [output_sup, output_min_sup, xhat_sup, xhat_min_sup, _, loss_pn_sup, loss_nn_sup] = net(data_sup, label_sup)\n",
    "                if global_step == 0:\n",
    "                    for ema_param, param in zip(ema_net.collect_params().values(),net.collect_params().values()):\n",
    "                        ema_param.initialize(init=mx.initializer.Constant(param.data()), ctx=ctx)\n",
    "                [output_sup_ema, output_min_sup_ema, _, _, _, _, _] = ema_net(data_sup, label_sup)\n",
    "                loss_xentropy_sup = opt.alpha_max * criterion(output_sup, label_sup) + opt.alpha_min * criterion(output_min_sup, label_sup)\n",
    "                loss_drm_sup = opt.alpha_max * L2_loss(xhat_sup, data_sup) + opt.alpha_min * L2_loss(xhat_min_sup, data_sup)\n",
    "                softmax_sup = opt.alpha_max * nd.softmax(output_sup) + opt.alpha_min * nd.softmax(output_min_sup)\n",
    "                softmax_sup_ema = opt.alpha_max * nd.softmax(output_sup_ema) + opt.alpha_min * nd.softmax(output_min_sup_ema)\n",
    "                loss_kl_sup = -nd.sum(nd.log(10.0*softmax_sup + 1e-8) * softmax_sup, axis=1)\n",
    "                loss_consistent_sup = L2_loss(softmax_sup, softmax_sup_ema)\n",
    "                loss = loss_xentropy_sup + opt.alpha_drm * loss_drm_sup + opt.alpha_kl * loss_kl_sup + opt.alpha_nn * loss_nn_sup + opt.alpha_pn * loss_pn_sup + opt.alpha_consistent * loss_consistent_sup\n",
    "                \n",
    "            loss.backward()\n",
    "            trainer.step(bs)\n",
    "            global_step += 1\n",
    "            if global_step < 40000:\n",
    "                update_ema_variables(net, ema_net, ema_decay[0], global_step)\n",
    "            else:\n",
    "                update_ema_variables(net, ema_net, ema_decay[1], global_step)\n",
    "            \n",
    "            loss_drm = loss_drm_sup\n",
    "            loss_pn = loss_pn_sup\n",
    "            loss_xentropy = loss_xentropy_sup\n",
    "            loss_kl = loss_kl_sup\n",
    "            loss_nn = loss_nn_sup\n",
    "            \n",
    "            train_loss_xentropy += nd.mean(loss_xentropy).asscalar()\n",
    "            train_loss_drm += nd.mean(loss_drm).asscalar()\n",
    "            train_loss_pn += nd.mean(loss_pn).asscalar()\n",
    "            train_loss_kl += nd.mean(loss_kl).asscalar()\n",
    "            train_loss_nn += nd.mean(loss_nn).asscalar()\n",
    "            train_loss += nd.mean(loss).asscalar()\n",
    "            correct += get_acc(opt.alpha_max * output_sup + opt.alpha_min * output_min_sup, label_sup)\n",
    "            correct2 += opt.alpha_max * get_acc(output_sup, label_sup) + opt.alpha_min * get_acc(output_min_sup, label_sup)\n",
    "            correctmax += get_acc(output_sup, label_sup)\n",
    "            correctmin += get_acc(output_min_sup, label_sup)\n",
    "            \n",
    "            total += bs\n",
    "            num_batch_train += 1\n",
    "            iter_indx += 1\n",
    "        \n",
    "        writer.add_scalars('loss', {'train': train_loss / num_batch_train}, epoch)\n",
    "        writer.add_scalars('loss_xentropy', {'train': train_loss_xentropy / num_batch_train}, epoch)\n",
    "        writer.add_scalars('loss_drm', {'train': train_loss_drm / num_batch_train}, epoch)\n",
    "        writer.add_scalars('loss_pn', {'train': train_loss_pn / num_batch_train}, epoch)\n",
    "        writer.add_scalars('loss_kl', {'train': train_loss_kl / num_batch_train}, epoch)\n",
    "        writer.add_scalars('loss_nn', {'train': train_loss_nn / num_batch_train}, epoch)\n",
    "        writer.add_scalars('acc', {'train': correct / total}, epoch)\n",
    "        writer.add_scalars('acc', {'train2': correct2 / total}, epoch)\n",
    "        writer.add_scalars('acc', {'trainmax': correctmax / total}, epoch)\n",
    "        writer.add_scalars('acc', {'trainmin': correctmin / total}, epoch)\n",
    "        \n",
    "        cur_time = datetime.datetime.now()\n",
    "        h, remainder = divmod((cur_time - prev_time).seconds, 3600)\n",
    "        m, s = divmod(remainder, 60)\n",
    "        time_str = \"Time %02d:%02d:%02d\" % (h, m, s)\n",
    "        if valid_data is not None:\n",
    "            valid_acc, valid_acc2, valid_accmax, valid_accmin, valid_loss_xentropy, valid_loss_drm, valid_loss_pn, valid_loss_kl, valid_loss_nn, valid_loss, num_batch_valid = test(net, valid_data, ctx)\n",
    "            best_valid_acc, best_valid_acc2, best_valid_accmax, best_valid_accmin = save_best(net, 'best', valid_acc, valid_acc2, valid_accmax, valid_accmin, best_valid_acc, best_valid_acc2, best_valid_accmax, best_valid_accmin)\n",
    "            write_results(writer, 'valid', valid_acc, valid_acc2, valid_accmax, valid_accmin, valid_loss_xentropy, valid_loss_drm, valid_loss_pn, valid_loss_kl, valid_loss_nn, valid_loss, num_batch_valid, epoch)\n",
    "            epoch_str = (\"Epoch %d. Train Loss: %f, Train Xent: %f, Train Reconst: %f, Train Pn: %f, Train acc %f, Valid Loss: %f, Valid acc %f, Valid acc2 %f, Valid accmax %f, Valid accmin %f, Best valid acc %f, Best valid acc2 %f, Best valid accmax %f, Best valid accmin %f, \"\n",
    "                         % (epoch, train_loss / num_batch_train, train_loss_xentropy / num_batch_train, train_loss_drm / num_batch_train, train_loss_pn / num_batch_train,\n",
    "                            correct / total, valid_loss / num_batch_valid, valid_acc, valid_acc2, valid_accmax, valid_accmin, best_valid_acc, best_valid_acc2, best_valid_accmax, best_valid_accmin))\n",
    "            \n",
    "            valid_acc, valid_acc2, valid_accmax, valid_accmin, valid_loss_xentropy, valid_loss_drm, valid_loss_pn, valid_loss_kl, valid_loss_nn, valid_loss, num_batch_valid = test(ema_net, valid_data, ctx)\n",
    "            best_valid_acc_ema, best_valid_acc_ema2, best_valid_acc_emamax, best_valid_acc_emamin = save_best(ema_net, 'best_ema', valid_acc, valid_acc2, valid_accmax, valid_accmin, best_valid_acc_ema, best_valid_acc_ema2, best_valid_acc_emamax, best_valid_acc_emamin)\n",
    "            write_results(writer, 'valid_ema', valid_acc, valid_acc2, valid_accmax, valid_accmin, valid_loss_xentropy, valid_loss_drm, valid_loss_pn, valid_loss_kl, valid_loss_nn, valid_loss, num_batch_valid, epoch)\n",
    "            epoch_str_ema = (\"Epoch %d. Valid Loss EMA: %f, Valid acc EMA %f, Valid acc2 EMA %f, Valid accmax EMA %f, Valid accmin EMA %f, Best valid acc EMA %f, Best valid acc2 EMA %f, Best valid accmax EMA %f, Best valid accmin EMA %f, \"\n",
    "                         % (epoch, valid_loss / num_batch_valid, valid_acc, valid_acc2, valid_accmax, valid_accmin, best_valid_acc_ema, best_valid_acc_ema2, best_valid_acc_emamax, best_valid_acc_emamin))\n",
    "            # net.collect_params().save('%s/%s_latest.params'%(opt.model_dir, opt.exp_name))\n",
    "            if not epoch % 20:\n",
    "                net.collect_params().save('%s/%s_epoch_%i.params'%(opt.model_dir, opt.exp_name, epoch))\n",
    "                ema_net.collect_params().save('%s/%s_ema_epoch_%i.params'%(opt.model_dir, opt.exp_name, epoch))\n",
    "        else:\n",
    "            epoch_str = (\"Epoch %d. Loss: %f, Train acc %f, \"\n",
    "                         % (epoch, train_loss / num_batch_train,\n",
    "                            correct / total))\n",
    "        prev_time = cur_time\n",
    "        print(epoch_str + time_str + ', lr ' + str(trainer.learning_rate))\n",
    "        print(epoch_str_ema + time_str)\n",
    "        \n",
    "    return best_valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 500\n",
    "learning_rate = 0.15\n",
    "weight_decay = 5e-4\n",
    "lr_decay = 0.1\n",
    "ema_decay = [0.99, 0.999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train(num_exp, ctx):\n",
    "    valid_acc = 0\n",
    "    for i in range(num_exp):\n",
    "        ### CIFAR VGG_DRM\n",
    "        model = NRM('AllConv13', batch_size=opt.batch_size, num_class=10, use_bias=opt.use_bias, use_bn=opt.use_bn, do_topdown=opt.do_topdown, do_countpath=opt.do_countpath, do_pn=opt.do_pn, relu_td=opt.relu_td, do_nn=opt.do_nn, min_max=opt.min_max)\n",
    "        for param in model.collect_params().values():\n",
    "            if param.name.find('conv') != -1 or param.name.find('dense') != -1:\n",
    "                if param.name.find('weight') != -1:\n",
    "                    param.initialize(init=mx.initializer.Xavier(), ctx=ctx)\n",
    "                else:\n",
    "                    param.initialize(init=mx.init.Zero(), ctx=ctx)\n",
    "            elif param.name.find('batchnorm') != -1 or param.name.find('instancenorm') != -1:\n",
    "                if param.name.find('gamma') != -1:\n",
    "                    param.initialize(init=Normal(mean=1, sigma=0.02), ctx=ctx)\n",
    "                else:\n",
    "                    param.initialize(init=mx.init.Zero(), ctx=ctx)\n",
    "            elif param.name.find('biasadder') != -1:\n",
    "                param.initialize(init=mx.init.Zero(), ctx=ctx)\n",
    "        \n",
    "        # model.collect_params().load('%s/%s_epoch_%i.params'%(opt.model_dir, opt.exp_name, 380), ctx=ctx)\n",
    "        ema_model = NRM('AllConv13', batch_size=opt.batch_size, num_class=10, use_bias=opt.use_bias, use_bn=opt.use_bn, do_topdown=opt.do_topdown, do_countpath=opt.do_countpath, do_pn=opt.do_pn, relu_td=opt.relu_td, do_nn=opt.do_nn, min_max=opt.min_max)\n",
    "        # model.hybridize()\n",
    "        relu_indx = []\n",
    "        \n",
    "        for i in range(len(model.features._children)):\n",
    "            if model.features._children[i].name.find('relu') != -1:\n",
    "                relu_indx.append(i)\n",
    "                \n",
    "        acc = train(model, ema_model, train_data_sup, valid_data, num_epochs, learning_rate, weight_decay, ctx, lr_decay, relu_indx)\n",
    "        print('Validation Accuracy - Run %i = %f'%(i, acc))\n",
    "        valid_acc += acc\n",
    "\n",
    "    print('Validation Accuracy = %f'%(valid_acc/num_exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Train Loss: 2.966746, Train Xent: 1.994143, Train Reconst: 0.652957, Train Pn: 0.006875, Train acc 0.360295, Valid Loss: 3.718383, Valid acc 0.450100, Valid acc2 0.443950, Valid accmax 0.441200, Valid accmin 0.446700, Best valid acc 0.450100, Best valid acc2 0.443950, Best valid accmax 0.441200, Best valid accmin 0.446700, Time 00:12:56, lr 0.001\n",
      "Epoch 0. Valid Loss EMA: 3.139538, Valid acc EMA 0.454300, Valid acc2 EMA 0.454050, Valid accmax EMA 0.453900, Valid accmin EMA 0.454200, Best valid acc EMA 0.454300, Best valid acc2 EMA 0.454050, Best valid accmax EMA 0.453900, Best valid accmin EMA 0.454200, Time 00:12:56\n",
      "Epoch 1. Train Loss: 0.334188, Train Xent: 1.283832, Train Reconst: 0.195431, Train Pn: 0.006830, Train acc 0.571727, Valid Loss: 7.696186, Valid acc 0.635100, Valid acc2 0.626500, Valid accmax 0.627500, Valid accmin 0.625500, Best valid acc 0.635100, Best valid acc2 0.626500, Best valid accmax 0.627500, Best valid accmin 0.625500, Time 00:13:34, lr 0.001\n",
      "Epoch 1. Valid Loss EMA: 5.059958, Valid acc EMA 0.657400, Valid acc2 EMA 0.652550, Valid accmax EMA 0.654100, Valid accmin EMA 0.651000, Best valid acc EMA 0.657400, Best valid acc2 EMA 0.652550, Best valid accmax EMA 0.654100, Best valid accmin EMA 0.651000, Time 00:13:34\n",
      "Epoch 2. Train Loss: -0.402405, Train Xent: 0.863564, Train Reconst: 0.121430, Train Pn: 0.006637, Train acc 0.706352, Valid Loss: 2.680879, Valid acc 0.725900, Valid acc2 0.709750, Valid accmax 0.703400, Valid accmin 0.716100, Best valid acc 0.725900, Best valid acc2 0.709750, Best valid accmax 0.703400, Best valid accmin 0.716100, Time 00:13:35, lr 0.001\n",
      "Epoch 2. Valid Loss EMA: 5.133540, Valid acc EMA 0.738900, Valid acc2 EMA 0.736600, Valid accmax EMA 0.736500, Valid accmin EMA 0.736700, Best valid acc EMA 0.738900, Best valid acc2 EMA 0.736600, Best valid accmax EMA 0.736500, Best valid accmin EMA 0.736700, Time 00:13:35\n",
      "Epoch 3. Train Loss: -0.767318, Train Xent: 0.658948, Train Reconst: 0.090078, Train Pn: 0.006801, Train acc 0.767375, Valid Loss: 4.169928, Valid acc 0.752900, Valid acc2 0.742400, Valid accmax 0.742900, Valid accmin 0.741900, Best valid acc 0.752900, Best valid acc2 0.742400, Best valid accmax 0.742900, Best valid accmin 0.741900, Time 00:13:34, lr 0.001\n",
      "Epoch 3. Valid Loss EMA: 4.684931, Valid acc EMA 0.779300, Valid acc2 EMA 0.775550, Valid accmax EMA 0.776500, Valid accmin EMA 0.774600, Best valid acc EMA 0.779300, Best valid acc2 EMA 0.775550, Best valid accmax EMA 0.776500, Best valid accmin EMA 0.774600, Time 00:13:34\n",
      "Epoch 4. Train Loss: -0.977683, Train Xent: 0.535604, Train Reconst: 0.074032, Train Pn: 0.007047, Train acc 0.797727, Valid Loss: 2.955697, Valid acc 0.771600, Valid acc2 0.755100, Valid accmax 0.766400, Valid accmin 0.743800, Best valid acc 0.771600, Best valid acc2 0.755100, Best valid accmax 0.766400, Best valid accmin 0.743800, Time 00:13:37, lr 0.001\n",
      "Epoch 4. Valid Loss EMA: 3.514608, Valid acc EMA 0.794900, Valid acc2 EMA 0.789400, Valid accmax EMA 0.789000, Valid accmin EMA 0.789800, Best valid acc EMA 0.794900, Best valid acc2 EMA 0.789400, Best valid accmax EMA 0.789000, Best valid accmin EMA 0.789800, Time 00:13:37\n",
      "Epoch 5. Train Loss: -1.121634, Train Xent: 0.451272, Train Reconst: 0.064605, Train Pn: 0.007254, Train acc 0.819375, Valid Loss: 3.105041, Valid acc 0.783000, Valid acc2 0.768150, Valid accmax 0.768900, Valid accmin 0.767400, Best valid acc 0.783000, Best valid acc2 0.768150, Best valid accmax 0.768900, Best valid accmin 0.767400, Time 00:13:32, lr 0.001\n",
      "Epoch 5. Valid Loss EMA: 3.333755, Valid acc EMA 0.808200, Valid acc2 EMA 0.802000, Valid accmax EMA 0.800500, Valid accmin EMA 0.803500, Best valid acc EMA 0.808200, Best valid acc2 EMA 0.802000, Best valid accmax EMA 0.800500, Best valid accmin EMA 0.803500, Time 00:13:32\n",
      "Epoch 6. Train Loss: -1.212607, Train Xent: 0.397246, Train Reconst: 0.059430, Train Pn: 0.007610, Train acc 0.832682, Valid Loss: 2.717426, Valid acc 0.793000, Valid acc2 0.774700, Valid accmax 0.774100, Valid accmin 0.775300, Best valid acc 0.793000, Best valid acc2 0.774700, Best valid accmax 0.774100, Best valid accmin 0.775300, Time 00:13:33, lr 0.001\n",
      "Epoch 6. Valid Loss EMA: 2.763611, Valid acc EMA 0.811500, Valid acc2 EMA 0.805700, Valid accmax EMA 0.808000, Valid accmin EMA 0.803400, Best valid acc EMA 0.811500, Best valid acc2 EMA 0.805700, Best valid accmax EMA 0.808000, Best valid accmin EMA 0.803500, Time 00:13:33\n",
      "Epoch 7. Train Loss: -1.302626, Train Xent: 0.344552, Train Reconst: 0.057073, Train Pn: 0.007827, Train acc 0.843943, Valid Loss: 2.768089, Valid acc 0.792900, Valid acc2 0.777600, Valid accmax 0.774800, Valid accmin 0.780400, Best valid acc 0.793000, Best valid acc2 0.777600, Best valid accmax 0.774800, Best valid accmin 0.780400, Time 00:13:33, lr 0.001\n",
      "Epoch 7. Valid Loss EMA: 2.603187, Valid acc EMA 0.814800, Valid acc2 EMA 0.808400, Valid accmax EMA 0.808600, Valid accmin EMA 0.808200, Best valid acc EMA 0.814800, Best valid acc2 EMA 0.808400, Best valid accmax EMA 0.808600, Best valid accmin EMA 0.808200, Time 00:13:33\n",
      "Epoch 8. Train Loss: -1.362280, Train Xent: 0.311895, Train Reconst: 0.053403, Train Pn: 0.007972, Train acc 0.851080, Valid Loss: 2.772236, Valid acc 0.796000, Valid acc2 0.777700, Valid accmax 0.774600, Valid accmin 0.780800, Best valid acc 0.796000, Best valid acc2 0.777700, Best valid accmax 0.774800, Best valid accmin 0.780800, Time 00:13:36, lr 0.001\n",
      "Epoch 8. Valid Loss EMA: 2.762532, Valid acc EMA 0.819600, Valid acc2 EMA 0.813250, Valid accmax EMA 0.814700, Valid accmin EMA 0.811800, Best valid acc EMA 0.819600, Best valid acc2 EMA 0.813250, Best valid accmax EMA 0.814700, Best valid accmin EMA 0.811800, Time 00:13:36\n",
      "Epoch 9. Train Loss: -1.406504, Train Xent: 0.284393, Train Reconst: 0.052059, Train Pn: 0.008200, Train acc 0.857580, Valid Loss: 2.826868, Valid acc 0.812500, Valid acc2 0.793500, Valid accmax 0.794500, Valid accmin 0.792500, Best valid acc 0.812500, Best valid acc2 0.793500, Best valid accmax 0.794500, Best valid accmin 0.792500, Time 00:13:37, lr 0.001\n",
      "Epoch 9. Valid Loss EMA: 2.528903, Valid acc EMA 0.823100, Valid acc2 EMA 0.820100, Valid accmax EMA 0.819100, Valid accmin EMA 0.821100, Best valid acc EMA 0.823100, Best valid acc2 EMA 0.820100, Best valid accmax EMA 0.819100, Best valid accmin EMA 0.821100, Time 00:13:37\n",
      "Epoch 10. Train Loss: -1.448676, Train Xent: 0.259335, Train Reconst: 0.053034, Train Pn: 0.008352, Train acc 0.862898, Valid Loss: 3.362780, Valid acc 0.807200, Valid acc2 0.789200, Valid accmax 0.791300, Valid accmin 0.787100, Best valid acc 0.812500, Best valid acc2 0.793500, Best valid accmax 0.794500, Best valid accmin 0.792500, Time 00:13:36, lr 0.001\n",
      "Epoch 10. Valid Loss EMA: 2.989708, Valid acc EMA 0.824500, Valid acc2 EMA 0.815350, Valid accmax EMA 0.815000, Valid accmin EMA 0.815700, Best valid acc EMA 0.824500, Best valid acc2 EMA 0.820100, Best valid accmax EMA 0.819100, Best valid accmin EMA 0.821100, Time 00:13:36\n",
      "Epoch 11. Train Loss: -1.484002, Train Xent: 0.235654, Train Reconst: 0.055454, Train Pn: 0.008329, Train acc 0.866795, Valid Loss: 3.524484, Valid acc 0.802800, Valid acc2 0.783300, Valid accmax 0.788200, Valid accmin 0.778400, Best valid acc 0.812500, Best valid acc2 0.793500, Best valid accmax 0.794500, Best valid accmin 0.792500, Time 00:13:36, lr 0.001\n",
      "Epoch 11. Valid Loss EMA: 3.457160, Valid acc EMA 0.828700, Valid acc2 EMA 0.821850, Valid accmax EMA 0.822200, Valid accmin EMA 0.821500, Best valid acc EMA 0.828700, Best valid acc2 EMA 0.821850, Best valid accmax EMA 0.822200, Best valid accmin EMA 0.821500, Time 00:13:36\n",
      "Epoch 12. Train Loss: -1.499827, Train Xent: 0.227830, Train Reconst: 0.064250, Train Pn: 0.008408, Train acc 0.869477, Valid Loss: 3.513888, Valid acc 0.806200, Valid acc2 0.790950, Valid accmax 0.786400, Valid accmin 0.795500, Best valid acc 0.812500, Best valid acc2 0.793500, Best valid accmax 0.794500, Best valid accmin 0.795500, Time 00:13:39, lr 0.001\n",
      "Epoch 12. Valid Loss EMA: 4.109933, Valid acc EMA 0.828200, Valid acc2 EMA 0.820850, Valid accmax EMA 0.822900, Valid accmin EMA 0.818800, Best valid acc EMA 0.828700, Best valid acc2 EMA 0.821850, Best valid accmax EMA 0.822900, Best valid accmin EMA 0.821500, Time 00:13:39\n",
      "Epoch 13. Train Loss: -1.535974, Train Xent: 0.207149, Train Reconst: 0.062379, Train Pn: 0.008229, Train acc 0.873216, Valid Loss: 3.031520, Valid acc 0.809200, Valid acc2 0.794350, Valid accmax 0.799100, Valid accmin 0.789600, Best valid acc 0.812500, Best valid acc2 0.794350, Best valid accmax 0.799100, Best valid accmin 0.795500, Time 00:13:37, lr 0.001\n",
      "Epoch 13. Valid Loss EMA: 3.774198, Valid acc EMA 0.827400, Valid acc2 EMA 0.820350, Valid accmax EMA 0.820400, Valid accmin EMA 0.820300, Best valid acc EMA 0.828700, Best valid acc2 EMA 0.821850, Best valid accmax EMA 0.822900, Best valid accmin EMA 0.821500, Time 00:13:37\n",
      "Epoch 14. Train Loss: -1.547580, Train Xent: 0.198355, Train Reconst: 0.066153, Train Pn: 0.008623, Train acc 0.876352, Valid Loss: 3.418282, Valid acc 0.812300, Valid acc2 0.796000, Valid accmax 0.794900, Valid accmin 0.797100, Best valid acc 0.812500, Best valid acc2 0.796000, Best valid accmax 0.799100, Best valid accmin 0.797100, Time 00:13:39, lr 0.001\n",
      "Epoch 14. Valid Loss EMA: 3.701382, Valid acc EMA 0.829200, Valid acc2 EMA 0.819200, Valid accmax EMA 0.819000, Valid accmin EMA 0.819400, Best valid acc EMA 0.829200, Best valid acc2 EMA 0.821850, Best valid accmax EMA 0.822900, Best valid accmin EMA 0.821500, Time 00:13:39\n",
      "Epoch 15. Train Loss: -1.558387, Train Xent: 0.194752, Train Reconst: 0.057568, Train Pn: 0.008594, Train acc 0.876420, Valid Loss: 2.115193, Valid acc 0.807500, Valid acc2 0.790300, Valid accmax 0.784900, Valid accmin 0.795700, Best valid acc 0.812500, Best valid acc2 0.796000, Best valid accmax 0.799100, Best valid accmin 0.797100, Time 00:13:35, lr 0.001\n",
      "Epoch 15. Valid Loss EMA: 2.563360, Valid acc EMA 0.828700, Valid acc2 EMA 0.820650, Valid accmax EMA 0.822000, Valid accmin EMA 0.819300, Best valid acc EMA 0.829200, Best valid acc2 EMA 0.821850, Best valid accmax EMA 0.822900, Best valid accmin EMA 0.821500, Time 00:13:35\n",
      "Epoch 16. Train Loss: -1.579736, Train Xent: 0.184812, Train Reconst: 0.059188, Train Pn: 0.008466, Train acc 0.878500, Valid Loss: 2.895441, Valid acc 0.814900, Valid acc2 0.797850, Valid accmax 0.797200, Valid accmin 0.798500, Best valid acc 0.814900, Best valid acc2 0.797850, Best valid accmax 0.799100, Best valid accmin 0.798500, Time 00:13:36, lr 0.001\n",
      "Epoch 16. Valid Loss EMA: 3.195451, Valid acc EMA 0.831200, Valid acc2 EMA 0.822050, Valid accmax EMA 0.822400, Valid accmin EMA 0.821700, Best valid acc EMA 0.831200, Best valid acc2 EMA 0.822050, Best valid accmax EMA 0.822900, Best valid accmin EMA 0.821700, Time 00:13:36\n",
      "Epoch 17. Train Loss: -1.586600, Train Xent: 0.178873, Train Reconst: 0.059728, Train Pn: 0.008622, Train acc 0.878386, Valid Loss: 3.161338, Valid acc 0.817300, Valid acc2 0.799450, Valid accmax 0.804900, Valid accmin 0.794000, Best valid acc 0.817300, Best valid acc2 0.799450, Best valid accmax 0.804900, Best valid accmin 0.798500, Time 00:13:33, lr 0.001\n",
      "Epoch 17. Valid Loss EMA: 2.975443, Valid acc EMA 0.827000, Valid acc2 EMA 0.820950, Valid accmax EMA 0.822300, Valid accmin EMA 0.819600, Best valid acc EMA 0.831200, Best valid acc2 EMA 0.822050, Best valid accmax EMA 0.822900, Best valid accmin EMA 0.821700, Time 00:13:33\n",
      "Epoch 18. Train Loss: -1.598842, Train Xent: 0.174769, Train Reconst: 0.055018, Train Pn: 0.008548, Train acc 0.881830, Valid Loss: 3.622913, Valid acc 0.814500, Valid acc2 0.798600, Valid accmax 0.800300, Valid accmin 0.796900, Best valid acc 0.817300, Best valid acc2 0.799450, Best valid accmax 0.804900, Best valid accmin 0.798500, Time 00:13:30, lr 0.001\n",
      "Epoch 18. Valid Loss EMA: 2.645358, Valid acc EMA 0.830400, Valid acc2 EMA 0.821050, Valid accmax EMA 0.819700, Valid accmin EMA 0.822400, Best valid acc EMA 0.831200, Best valid acc2 EMA 0.822050, Best valid accmax EMA 0.822900, Best valid accmin EMA 0.822400, Time 00:13:30\n",
      "Epoch 19. Train Loss: -1.617536, Train Xent: 0.167329, Train Reconst: 0.056955, Train Pn: 0.008478, Train acc 0.882432, Valid Loss: 2.835154, Valid acc 0.817600, Valid acc2 0.800900, Valid accmax 0.802900, Valid accmin 0.798900, Best valid acc 0.817600, Best valid acc2 0.800900, Best valid accmax 0.804900, Best valid accmin 0.798900, Time 00:13:31, lr 0.001\n",
      "Epoch 19. Valid Loss EMA: 3.032305, Valid acc EMA 0.829800, Valid acc2 EMA 0.822500, Valid accmax EMA 0.824400, Valid accmin EMA 0.820600, Best valid acc EMA 0.831200, Best valid acc2 EMA 0.822500, Best valid accmax EMA 0.824400, Best valid accmin EMA 0.822400, Time 00:13:31\n",
      "Epoch 20. Train Loss: -1.523539, Train Xent: 0.173688, Train Reconst: 0.113029, Train Pn: 0.026268, Train acc 0.881170, Valid Loss: 2.202449, Valid acc 0.820600, Valid acc2 0.803900, Valid accmax 0.809900, Valid accmin 0.797900, Best valid acc 0.820600, Best valid acc2 0.803900, Best valid accmax 0.809900, Best valid accmin 0.798900, Time 00:13:29, lr 0.15\n",
      "Epoch 20. Valid Loss EMA: 1.827410, Valid acc EMA 0.834400, Valid acc2 EMA 0.826500, Valid accmax EMA 0.827300, Valid accmin EMA 0.825700, Best valid acc EMA 0.834400, Best valid acc2 EMA 0.826500, Best valid accmax EMA 0.827300, Best valid accmin EMA 0.825700, Time 00:13:29\n",
      "Epoch 21. Train Loss: -1.685572, Train Xent: 0.116102, Train Reconst: 0.076435, Train Pn: 0.022312, Train acc 0.890193, Valid Loss: 2.157422, Valid acc 0.821500, Valid acc2 0.804800, Valid accmax 0.806800, Valid accmin 0.802800, Best valid acc 0.821500, Best valid acc2 0.804800, Best valid accmax 0.809900, Best valid accmin 0.802800, Time 00:13:29, lr 0.14781331798330893\n",
      "Epoch 21. Valid Loss EMA: 1.790223, Valid acc EMA 0.836300, Valid acc2 EMA 0.828650, Valid accmax EMA 0.828900, Valid accmin EMA 0.828400, Best valid acc EMA 0.836300, Best valid acc2 EMA 0.828650, Best valid accmax EMA 0.828900, Best valid accmin EMA 0.828400, Time 00:13:29\n",
      "Epoch 22. Train Loss: -1.704318, Train Xent: 0.109407, Train Reconst: 0.074587, Train Pn: 0.021757, Train acc 0.893057, Valid Loss: 2.257729, Valid acc 0.814200, Valid acc2 0.784000, Valid accmax 0.791600, Valid accmin 0.776400, Best valid acc 0.821500, Best valid acc2 0.804800, Best valid accmax 0.809900, Best valid accmin 0.802800, Time 00:13:30, lr 0.14565851315489867\n",
      "Epoch 22. Valid Loss EMA: 1.691358, Valid acc EMA 0.840400, Valid acc2 EMA 0.830900, Valid accmax EMA 0.830800, Valid accmin EMA 0.831000, Best valid acc EMA 0.840400, Best valid acc2 EMA 0.830900, Best valid accmax EMA 0.830800, Best valid accmin EMA 0.831000, Time 00:13:30\n",
      "Epoch 23. Train Loss: -1.717116, Train Xent: 0.105009, Train Reconst: 0.069438, Train Pn: 0.021559, Train acc 0.895034, Valid Loss: 2.309961, Valid acc 0.814800, Valid acc2 0.797000, Valid accmax 0.793000, Valid accmin 0.801000, Best valid acc 0.821500, Best valid acc2 0.804800, Best valid accmax 0.809900, Best valid accmin 0.802800, Time 00:13:29, lr 0.14353512081294018\n",
      "Epoch 23. Valid Loss EMA: 1.694062, Valid acc EMA 0.841400, Valid acc2 EMA 0.833650, Valid accmax EMA 0.833600, Valid accmin EMA 0.833700, Best valid acc EMA 0.841400, Best valid acc2 EMA 0.833650, Best valid accmax EMA 0.833600, Best valid accmin EMA 0.833700, Time 00:13:29\n",
      "Epoch 24. Train Loss: -1.726573, Train Xent: 0.101892, Train Reconst: 0.063086, Train Pn: 0.021245, Train acc 0.894830, Valid Loss: 2.013980, Valid acc 0.801800, Valid acc2 0.781350, Valid accmax 0.774600, Valid accmin 0.788100, Best valid acc 0.821500, Best valid acc2 0.804800, Best valid accmax 0.809900, Best valid accmin 0.802800, Time 00:13:28, lr 0.14144268302997196\n",
      "Epoch 24. Valid Loss EMA: 1.432030, Valid acc EMA 0.842800, Valid acc2 EMA 0.833950, Valid accmax EMA 0.833400, Valid accmin EMA 0.834500, Best valid acc EMA 0.842800, Best valid acc2 EMA 0.833950, Best valid accmax EMA 0.833600, Best valid accmin EMA 0.834500, Time 00:13:28\n",
      "Epoch 25. Train Loss: -1.742262, Train Xent: 0.098600, Train Reconst: 0.058689, Train Pn: 0.020504, Train acc 0.895261, Valid Loss: 1.837232, Valid acc 0.799000, Valid acc2 0.778550, Valid accmax 0.768900, Valid accmin 0.788200, Best valid acc 0.821500, Best valid acc2 0.804800, Best valid accmax 0.809900, Best valid accmin 0.802800, Time 00:13:29, lr 0.13938074855414412\n",
      "Epoch 25. Valid Loss EMA: 1.349894, Valid acc EMA 0.843500, Valid acc2 EMA 0.834550, Valid accmax EMA 0.837300, Valid accmin EMA 0.831800, Best valid acc EMA 0.843500, Best valid acc2 EMA 0.834550, Best valid accmax EMA 0.837300, Best valid accmin EMA 0.834500, Time 00:13:29\n",
      "Epoch 26. Train Loss: -1.750876, Train Xent: 0.094012, Train Reconst: 0.061236, Train Pn: 0.020104, Train acc 0.895636, Valid Loss: 1.731930, Valid acc 0.815000, Valid acc2 0.795800, Valid accmax 0.797700, Valid accmin 0.793900, Best valid acc 0.821500, Best valid acc2 0.804800, Best valid accmax 0.809900, Best valid accmin 0.802800, Time 00:13:25, lr 0.13734887271190221\n",
      "Epoch 26. Valid Loss EMA: 1.409804, Valid acc EMA 0.840700, Valid acc2 EMA 0.831500, Valid accmax EMA 0.833900, Valid accmin EMA 0.829100, Best valid acc EMA 0.843500, Best valid acc2 EMA 0.834550, Best valid accmax EMA 0.837300, Best valid accmin EMA 0.834500, Time 00:13:25\n",
      "Epoch 27. Train Loss: -1.756877, Train Xent: 0.090690, Train Reconst: 0.056461, Train Pn: 0.019789, Train acc 0.897216, Valid Loss: 1.411093, Valid acc 0.825600, Valid acc2 0.807900, Valid accmax 0.816000, Valid accmin 0.799800, Best valid acc 0.825600, Best valid acc2 0.807900, Best valid accmax 0.816000, Best valid accmin 0.802800, Time 00:13:29, lr 0.1353466173120895\n",
      "Epoch 27. Valid Loss EMA: 1.312928, Valid acc EMA 0.840800, Valid acc2 EMA 0.832000, Valid accmax EMA 0.833800, Valid accmin EMA 0.830200, Best valid acc EMA 0.843500, Best valid acc2 EMA 0.834550, Best valid accmax EMA 0.837300, Best valid accmin EMA 0.834500, Time 00:13:29\n",
      "Epoch 28. Train Loss: -1.755627, Train Xent: 0.089497, Train Reconst: 0.058533, Train Pn: 0.019730, Train acc 0.898136, Valid Loss: 1.380251, Valid acc 0.835900, Valid acc2 0.811900, Valid accmax 0.814000, Valid accmin 0.809800, Best valid acc 0.835900, Best valid acc2 0.811900, Best valid accmax 0.816000, Best valid accmin 0.809800, Time 00:13:28, lr 0.1333735505514474\n",
      "Epoch 28. Valid Loss EMA: 1.286761, Valid acc EMA 0.845000, Valid acc2 EMA 0.836150, Valid accmax EMA 0.839000, Valid accmin EMA 0.833300, Best valid acc EMA 0.845000, Best valid acc2 EMA 0.836150, Best valid accmax EMA 0.839000, Best valid accmin EMA 0.834500, Time 00:13:28\n",
      "Epoch 29. Train Loss: -1.762855, Train Xent: 0.091427, Train Reconst: 0.054891, Train Pn: 0.019277, Train acc 0.898773, Valid Loss: 1.661974, Valid acc 0.815900, Valid acc2 0.794450, Valid accmax 0.800300, Valid accmin 0.788600, Best valid acc 0.835900, Best valid acc2 0.811900, Best valid accmax 0.816000, Best valid accmin 0.809800, Time 00:13:27, lr 0.1314292469214935\n",
      "Epoch 29. Valid Loss EMA: 1.177604, Valid acc EMA 0.841300, Valid acc2 EMA 0.832950, Valid accmax EMA 0.833100, Valid accmin EMA 0.832800, Best valid acc EMA 0.845000, Best valid acc2 EMA 0.836150, Best valid accmax EMA 0.839000, Best valid accmin EMA 0.834500, Time 00:13:27\n",
      "Epoch 30. Train Loss: -1.768303, Train Xent: 0.088006, Train Reconst: 0.057482, Train Pn: 0.018543, Train acc 0.898670, Valid Loss: 1.547742, Valid acc 0.813300, Valid acc2 0.798600, Valid accmax 0.801600, Valid accmin 0.795600, Best valid acc 0.835900, Best valid acc2 0.811900, Best valid accmax 0.816000, Best valid accmin 0.809800, Time 00:13:28, lr 0.12951328711675697\n",
      "Epoch 30. Valid Loss EMA: 1.183254, Valid acc EMA 0.844700, Valid acc2 EMA 0.834550, Valid accmax EMA 0.837100, Valid accmin EMA 0.832000, Best valid acc EMA 0.845000, Best valid acc2 EMA 0.836150, Best valid accmax EMA 0.839000, Best valid accmin EMA 0.834500, Time 00:13:28\n",
      "Epoch 31. Train Loss: -1.787971, Train Xent: 0.079953, Train Reconst: 0.052820, Train Pn: 0.018363, Train acc 0.899898, Valid Loss: 1.710273, Valid acc 0.820300, Valid acc2 0.805050, Valid accmax 0.804800, Valid accmin 0.805300, Best valid acc 0.835900, Best valid acc2 0.811900, Best valid accmax 0.816000, Best valid accmin 0.809800, Time 00:13:26, lr 0.12762525794435192\n",
      "Epoch 31. Valid Loss EMA: 1.289674, Valid acc EMA 0.840700, Valid acc2 EMA 0.832750, Valid accmax EMA 0.834400, Valid accmin EMA 0.831100, Best valid acc EMA 0.845000, Best valid acc2 EMA 0.836150, Best valid accmax EMA 0.839000, Best valid accmin EMA 0.834500, Time 00:13:26\n",
      "Epoch 32. Train Loss: -1.779724, Train Xent: 0.084963, Train Reconst: 0.052900, Train Pn: 0.018266, Train acc 0.899489, Valid Loss: 1.507045, Valid acc 0.825500, Valid acc2 0.809700, Valid accmax 0.815500, Valid accmin 0.803900, Best valid acc 0.835900, Best valid acc2 0.811900, Best valid accmax 0.816000, Best valid accmin 0.809800, Time 00:13:28, lr 0.12576475223486877\n",
      "Epoch 32. Valid Loss EMA: 1.188168, Valid acc EMA 0.844800, Valid acc2 EMA 0.836900, Valid accmax EMA 0.837700, Valid accmin EMA 0.836100, Best valid acc EMA 0.845000, Best valid acc2 EMA 0.836900, Best valid accmax EMA 0.839000, Best valid accmin EMA 0.836100, Time 00:13:28\n",
      "Epoch 33. Train Loss: -1.792115, Train Xent: 0.080497, Train Reconst: 0.054031, Train Pn: 0.017627, Train acc 0.900477, Valid Loss: 1.682226, Valid acc 0.827100, Valid acc2 0.806250, Valid accmax 0.800000, Valid accmin 0.812500, Best valid acc 0.835900, Best valid acc2 0.811900, Best valid accmax 0.816000, Best valid accmin 0.812500, Time 00:13:34, lr 0.12393136875456481\n",
      "Epoch 33. Valid Loss EMA: 1.094178, Valid acc EMA 0.844600, Valid acc2 EMA 0.834900, Valid accmax EMA 0.838400, Valid accmin EMA 0.831400, Best valid acc EMA 0.845000, Best valid acc2 EMA 0.836900, Best valid accmax EMA 0.839000, Best valid accmin EMA 0.836100, Time 00:13:34\n",
      "Epoch 34. Train Loss: -1.788365, Train Xent: 0.080986, Train Reconst: 0.058093, Train Pn: 0.017730, Train acc 0.901875, Valid Loss: 1.262767, Valid acc 0.833600, Valid acc2 0.819750, Valid accmax 0.821100, Valid accmin 0.818400, Best valid acc 0.835900, Best valid acc2 0.819750, Best valid accmax 0.821100, Best valid accmin 0.818400, Time 00:13:33, lr 0.12212471211883472\n",
      "Epoch 34. Valid Loss EMA: 0.992225, Valid acc EMA 0.843600, Valid acc2 EMA 0.836950, Valid accmax EMA 0.839500, Valid accmin EMA 0.834400, Best valid acc EMA 0.845000, Best valid acc2 EMA 0.836950, Best valid accmax EMA 0.839500, Best valid accmin EMA 0.836100, Time 00:13:33\n",
      "Epoch 35. Train Loss: -1.815750, Train Xent: 0.071650, Train Reconst: 0.048663, Train Pn: 0.016947, Train acc 0.902648, Valid Loss: 1.582330, Valid acc 0.823600, Valid acc2 0.810700, Valid accmax 0.813100, Valid accmin 0.808300, Best valid acc 0.835900, Best valid acc2 0.819750, Best valid accmax 0.821100, Best valid accmin 0.818400, Time 00:13:31, lr 0.12034439270694253\n",
      "Epoch 35. Valid Loss EMA: 1.100897, Valid acc EMA 0.843900, Valid acc2 EMA 0.837100, Valid accmax EMA 0.839000, Valid accmin EMA 0.835200, Best valid acc EMA 0.845000, Best valid acc2 EMA 0.837100, Best valid accmax EMA 0.839500, Best valid accmin EMA 0.836100, Time 00:13:31\n",
      "Epoch 36. Train Loss: -1.812932, Train Xent: 0.072661, Train Reconst: 0.048241, Train Pn: 0.016788, Train acc 0.902670, Valid Loss: 1.621100, Valid acc 0.825700, Valid acc2 0.800950, Valid accmax 0.794700, Valid accmin 0.807200, Best valid acc 0.835900, Best valid acc2 0.819750, Best valid accmax 0.821100, Best valid accmin 0.818400, Time 00:13:30, lr 0.11859002657799667\n",
      "Epoch 36. Valid Loss EMA: 1.034797, Valid acc EMA 0.844300, Valid acc2 EMA 0.835700, Valid accmax EMA 0.838000, Valid accmin EMA 0.833400, Best valid acc EMA 0.845000, Best valid acc2 EMA 0.837100, Best valid accmax EMA 0.839500, Best valid accmin EMA 0.836100, Time 00:13:30\n",
      "Epoch 37. Train Loss: -1.811272, Train Xent: 0.075098, Train Reconst: 0.053137, Train Pn: 0.016596, Train acc 0.902989, Valid Loss: 1.399077, Valid acc 0.828000, Valid acc2 0.805950, Valid accmax 0.799200, Valid accmin 0.812700, Best valid acc 0.835900, Best valid acc2 0.819750, Best valid accmax 0.821100, Best valid accmin 0.818400, Time 00:13:30, lr 0.11686123538814987\n",
      "Epoch 37. Valid Loss EMA: 0.996557, Valid acc EMA 0.844900, Valid acc2 EMA 0.837200, Valid accmax EMA 0.838800, Valid accmin EMA 0.835600, Best valid acc EMA 0.845000, Best valid acc2 EMA 0.837200, Best valid accmax EMA 0.839500, Best valid accmin EMA 0.836100, Time 00:13:30\n",
      "Epoch 38. Train Loss: -1.815038, Train Xent: 0.071375, Train Reconst: 0.056788, Train Pn: 0.016391, Train acc 0.903648, Valid Loss: 1.318608, Valid acc 0.835300, Valid acc2 0.819000, Valid accmax 0.818800, Valid accmin 0.819200, Best valid acc 0.835900, Best valid acc2 0.819750, Best valid accmax 0.821100, Best valid accmin 0.819200, Time 00:13:29, lr 0.11515764630900607\n",
      "Epoch 38. Valid Loss EMA: 1.024767, Valid acc EMA 0.846300, Valid acc2 EMA 0.837950, Valid accmax EMA 0.840200, Valid accmin EMA 0.835700, Best valid acc EMA 0.846300, Best valid acc2 EMA 0.837950, Best valid accmax EMA 0.840200, Best valid accmin EMA 0.836100, Time 00:13:29\n",
      "Epoch 39. Train Loss: -1.823999, Train Xent: 0.068934, Train Reconst: 0.059916, Train Pn: 0.016075, Train acc 0.904545, Valid Loss: 1.397028, Valid acc 0.819500, Valid acc2 0.796750, Valid accmax 0.792800, Valid accmin 0.800700, Best valid acc 0.835900, Best valid acc2 0.819750, Best valid accmax 0.821100, Best valid accmin 0.819200, Time 00:13:31, lr 0.11347889194721691\n",
      "Epoch 39. Valid Loss EMA: 1.034655, Valid acc EMA 0.844000, Valid acc2 EMA 0.837800, Valid accmax EMA 0.839300, Valid accmin EMA 0.836300, Best valid acc EMA 0.846300, Best valid acc2 EMA 0.837950, Best valid accmax EMA 0.840200, Best valid accmin EMA 0.836300, Time 00:13:31\n",
      "Epoch 40. Train Loss: -1.832529, Train Xent: 0.066271, Train Reconst: 0.053130, Train Pn: 0.015795, Train acc 0.903932, Valid Loss: 1.504136, Valid acc 0.828800, Valid acc2 0.813050, Valid accmax 0.811100, Valid accmin 0.815000, Best valid acc 0.835900, Best valid acc2 0.819750, Best valid accmax 0.821100, Best valid accmin 0.819200, Time 00:13:31, lr 0.1118246102652502\n",
      "Epoch 40. Valid Loss EMA: 1.007952, Valid acc EMA 0.847700, Valid acc2 EMA 0.838450, Valid accmax EMA 0.838900, Valid accmin EMA 0.838000, Best valid acc EMA 0.847700, Best valid acc2 EMA 0.838450, Best valid accmax EMA 0.840200, Best valid accmin EMA 0.838000, Time 00:13:31\n",
      "Epoch 41. Train Loss: -1.832596, Train Xent: 0.068313, Train Reconst: 0.052198, Train Pn: 0.015712, Train acc 0.905318, Valid Loss: 1.348994, Valid acc 0.829100, Valid acc2 0.810150, Valid accmax 0.813700, Valid accmin 0.806600, Best valid acc 0.835900, Best valid acc2 0.819750, Best valid accmax 0.821100, Best valid accmin 0.819200, Time 00:13:28, lr 0.11019444450331348\n",
      "Epoch 41. Valid Loss EMA: 1.044198, Valid acc EMA 0.845100, Valid acc2 EMA 0.838950, Valid accmax EMA 0.839100, Valid accmin EMA 0.838800, Best valid acc EMA 0.847700, Best valid acc2 EMA 0.838950, Best valid accmax EMA 0.840200, Best valid accmin EMA 0.838800, Time 00:13:28\n"
     ]
    }
   ],
   "source": [
    "run_train(1, ctx=opt.ctx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
